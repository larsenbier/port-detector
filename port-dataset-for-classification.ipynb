{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12747372,"sourceType":"datasetVersion","datasetId":8058305},{"sourceId":258737712,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ***************************************************************************\n# --------------------------------- Imports ---------------------------------\n# ***************************************************************************\n\nimport numpy as np # linear algebra\n\nimport os # file handling\nimport json # file handling\nimport pickle # file handling\n\nimport torch # deep learning\nimport torchvision # deep learning for computer vision\nfrom torch.utils.data import Dataset, DataLoader # shortcuts for writing dataset objects\n\nimport matplotlib.pyplot as plt # image saving","metadata":{"_uuid":"1756d946-6823-45ae-adb2-6e482fc8bb83","_cell_guid":"359f266f-f85d-4d4e-87aa-d10c08f18360","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-29T17:06:18.699473Z","iopub.execute_input":"2025-08-29T17:06:18.699848Z","iopub.status.idle":"2025-08-29T17:06:29.369883Z","shell.execute_reply.started":"2025-08-29T17:06:18.699823Z","shell.execute_reply":"2025-08-29T17:06:29.368608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ***************************************************************************\n# ----------------- --Object Detection Dataset Class ------------------------\n# ***************************************************************************\n\nclass PortDataset(Dataset):\n    def __init__(self,root,pkl_images,pkl_targets):\n        '''\n        dataset for Port object detection (the original data)\n    \n         Args:\n            root (str): the root path of the folder where the images live\n            pkl_images (str): the path of the pickled (list) version of the image filenames\n            pkl_labels (str): the path of the pickled (list) version of the image classes\n    \n        Note that roboflow did all the transforming before we downloaded the data. If we need more transformations, we can go back and download the unedited version, then implement our own transformations.\n        '''\n        self.root=root\n        self.filenames=pkl_images\n        self.targets=pkl_targets\n    \n    def __len__(self):\n        return len(self.filenames)\n    \n    def __getitem__(self,idx):\n        if type(idx) is not int:\n            raise ValueError(f'expected idx to be an integer, got {type(idx)}')\n        # Image tensor\n        image=torchvision.io.read_image(os.path.join(self.root,self.filenames[idx])).to(torch.float32)\n        # Targets tensor\n        boxes=torch.tensor(self.targets[idx]['boxes'])\n        labels=torch.tensor(self.targets[idx]['labels'])\n        targets={'boxes':boxes,'labels':labels}      \n        \n        return image,targets\n\n# ***************************************************************************\n# ------------------ Image Classification Dataset Class ---------------------\n# ***************************************************************************\n\nclass PortClassificationDataset(Dataset):\n    def __init__(self,root,pkl_images,pkl_s):\n        '''\n        dataset for Port classification (sub-images of oroginal PortDataset).\n        \n        Args:\n            root (str): the root path of the folder where the images live\n            pkl_images (str): the path of the pickled (list) version of the image filenames\n            pkl_labels (str): the path of the pickled (list) version of the image classes\n        \n        Returns:\n            torch.utils.data.Dataset: A dataset of the images and labels specified by pkl_images and pkl_labels.\n        \n        Note that roboflow did some transforming before we downloaded the data. If we need more transformations, we can implement our own through a data loader.\n        '''\n        self.root=root\n        self.images=pkl_images\n        self.labels=pkl_labels\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self,idx):\n        if type(idx) is not int:\n            raise ValueError(f'expected idx to be an integer, got {type(idx)}')\n        # Image tensor\n        image=torchvision.io.read_image(os.path.join(self.root,self.images[idx])).to(torch.float32)\n        # Labels tensor\n        label=torch.tensor(self.labels[idx]['labels'])   \n        \n        return image,label","metadata":{"_uuid":"8e6de8aa-2945-43c5-8d0e-0addbd3906f8","_cell_guid":"311ab288-be0d-455f-91d2-59ff8b0ebd2d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-29T17:06:29.371713Z","iopub.execute_input":"2025-08-29T17:06:29.372116Z","iopub.status.idle":"2025-08-29T17:06:29.384444Z","shell.execute_reply.started":"2025-08-29T17:06:29.372089Z","shell.execute_reply":"2025-08-29T17:06:29.383255Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ***************************************************************************\n# ---------- Turn COCO json Data into Usable Format (Lists) -----------------\n# ***************************************************************************\n# for each image we make a dictionary:\n        # boxes: (N,4) Tensor row=(x,y,width,height) (note the COCO data is in (x1,y1,x2,y1) format)\n        # labels: (N) Tensor element=class label\n\ndef pickle_data(subset,root):\n    '''\n    turns the data from port-by-ds-on-robolab into lists of filepaths, boxes, and labels which can be used by pytorch.\n    '''\n    if subset not in ['test','train','valid']:\n        raise ValueError(f'please enter the string \"test\", \"valid\", or \"train\". Received {subset}')\n    \n    # Read in COCO json data\n    fpath=f'{root}/{subset}/_annotations.coco.json'\n    with open(fpath,encoding='utf-8') as f:\n        data=json.load(f)\n        \n    # Make images: a list of the image pathways\n    images=[None]*len(data['images'])\n    \n    # Populate images\n    for image in data['images']:\n        idx=image['id']\n        images[idx]=os.path.join(root,subset,image['file_name'])\n        \n    # Make targets: a list of distinct dictionaries\n    targets=[None]*len(data['images'])\n    for i in range(len(targets)):\n        targets[i]={'boxes':[],'labels':[]}\n    \n    # Populate targets\n    for note in data['annotations']:\n        # Get image index\n        image_idx=note['image_id']\n        # change bounding box representation from (x,y,w,h) (upper-left and size) to (x1,y1,x2,y2) (upper-left and bottom-right)\n        x,y,w,h=note['bbox'].copy()\n        bbox=[x,y,x+w,y+h]\n        if bbox[0]>=bbox[2] or bbox[1]>=bbox[3]:\n            raise Exception(f'expected x1,y1 to be less than x2,y2 respectively. Got box {bbox}')\n        # Add box to d\n        targets[image_idx]['boxes'].append(bbox)\n        # Add label to d\n        targets[image_idx]['labels'].append(note['category_id'])\n    \n    # Check that boxes and labels are in bijective correspondence\n    total_boxes=0\n    for i in range(0,len(targets)):\n        assert(len(targets[i]['boxes'])==len(targets[i]['labels']))\n        total_boxes+=len(targets[i]['boxes'])\n\n    # Remove images with no labeled boxes\n    i=0\n    while i<len(images):\n        if len(targets[i]['boxes'])==0:\n            targets.pop(i)\n            images.pop(i)\n        else:\n            i+=1\n    \n    # Save data\n    with open(f'/kaggle/working/{subset}_images.pkl','wb') as f:\n        pickle.dump(images, f)\n    with open(f'/kaggle/working/{subset}_targets.pkl','wb') as f:\n        pickle.dump(targets, f)\n\n# generate pickled data\npickle_data('test','/kaggle/input/port-by-ds-on-robolab')\npickle_data('train','/kaggle/input/port-by-ds-on-robolab')\npickle_data('valid','/kaggle/input/port-by-ds-on-robolab')","metadata":{"_uuid":"d5fb1aa5-6e1e-4548-8d9a-3fd5e4b6cad2","_cell_guid":"e058a83b-bde0-47b3-bdda-c8fdccb005d0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-28T17:03:48.237080Z","iopub.execute_input":"2025-08-28T17:03:48.237407Z","iopub.status.idle":"2025-08-28T17:03:48.277878Z","shell.execute_reply.started":"2025-08-28T17:03:48.237381Z","shell.execute_reply":"2025-08-28T17:03:48.276993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ***************************************************************************\n# --------- Generate Classification Data from Object Detection Data ---------\n# ***************************************************************************\n# The data are stored in '/kaggle/working/classifier_{subset}/', where {subset} is train, test, or valid.\n# Both the positive and negative samples are stored in that directory.\n# Ordered lists of the image pathways (in the zipped folder) and their labels are also stored in the working directory for use in the dataset class.\n\ndef generate_samples(subset):\n    \"\"\"\n    Given the port images from port-by-ds-on-robolab intended for object detection, generates a classification dataset.\n    Extracts the positive images specified by the bounding boxes, and generates background images by random sampling of \n    the original image, checking each time that there is minimal overlap with existing boxes.\n    \"\"\"\n    ##############################################################################\n    # Background images (regions of images that do not overlap with bounding boxes)\n    \n    print(f'generating negative {subset} images...')\n    \n    train_images=pickle.load(open(f'/kaggle/working/{subset}_images.pkl','rb'))\n    train_targets=pickle.load(open(f'/kaggle/working/{subset}_targets.pkl','rb'))\n    root=f'/kaggle/input/port-by-ds-on-robolab/{subset}'\n    \n    w=132\n    h=132\n    overlap_threshold=0.05\n    max_attempts=60\n    \n    # make sample container\n    negative_samples=[]\n    \n    # make image folder\n    directory_name=f'/kaggle/working/classifier_{subset}'\n    image_list_path=f'classifier_{subset}'\n    try:\n        os.mkdir(directory_name)\n        print(f\"\\t\\tDirectory '{directory_name}' created successfully.\")\n    except FileExistsError:\n        print(f\"\\t\\tDirectory '{directory_name}' already exists.\")\n    \n    for i,path in enumerate(train_images):\n        for attempt in range(max_attempts):\n            # read in image\n            image=torchvision.io.read_image(os.path.join(root,path)).to(torch.float32)\n            n,m=image.shape[1:] # [H,W] (rows,cols)\n        \n            # pick box in range\n            np.random.seed(i*(attempt+1))\n            x1=np.random.randint(low=0,high=m-w)\n            y1=np.random.randint(low=0,high=n-h)\n            x2,y2=x1+w,y1+h\n        \n            # check for collisions\n            valid_box=True\n            for bbox in train_targets[i]['boxes']:\n                x3,y3,x4,y4=bbox\n                if x1<=x4 and y1<=y4 and x2>=x3 and y2>=y3: # overlapping boxes\n                    shared_area=(min(x2,x4)-max(x1,x3))*(min(y2,y4)-max(y1,y3))\n                    overlap=shared_area/(w*h)\n                    if max([shared_area/(w*h),shared_area/((x4-x3)*(y4-y3))])>=overlap_threshold: # one of the boxes is too covered\n                        valid_box=False\n                        break\n                \n            # save image\n            name=os.path.join(image_list_path,f'negative_train_{i}_attempt_{attempt}_dims_{h}x{w}.jpg')\n            if valid_box:\n                plt.imsave(name,image[:,y1:y2,x1:x2].permute((1,2,0)).detach().numpy().astype(np.uint8))\n                negative_samples.append(name)\n\n    neg_images=negative_samples\n    neg_labels=[torch.tensor(0) for f in neg_images]\n\n    #############################################################################\n    # Port images (extract sub-images defined by bounding boxes of original data)\n\n    print(f'generating positive {subset} images')\n    \n    dataset=PortDataset(f'/kaggle/input/port-by-ds-on-robolab/{subset}',\n                      pickle.load(open(f'/kaggle/working/{subset}_images.pkl','rb')),\n                      pickle.load(open(f'/kaggle/working/{subset}_targets.pkl','rb'))\n                     )\n    \n    # make image folder\n    directory_name=f'/kaggle/working/classifier_{subset}'\n    image_list_path=f'classifier_{subset}'\n    try:\n        os.mkdir(directory_name)\n        print(f\"\\t\\tDirectory '{directory_name}' created successfully.\")\n    except FileExistsError:\n        print(f\"\\t\\tDirectory '{directory_name}' already exists.\")\n    \n    pos_images=[]\n    pos_labels=[]\n    for i,(image,targets) in enumerate(dataset):\n        for j,box in enumerate(targets['boxes']):\n            x1,y1,x2,y2=[int(box[idx].item()) for idx in range(0,len(box))]\n            if (x2-x1)*(y2-y1)<=4096: # image too small\n                continue\n            name=os.path.join(image_list_path,f'image_{i}_box_{j}.jpg')\n            pos_images.append(name)\n            pos_labels.append(targets['labels'][j])\n\n            ########################################################################################################################\n            # Failed method: tried expanding the iamges by a multiplicative factor to help the model learn the surroundings of ports.\n            # Did not improve performance on the object detection task.\n            \n            # # add a little extra area to the sides:\n            # scale=1.35\n            # h,w=image.shape[1:]\n            # # get expaned range (within image)\n            # x_min=int(max(0,x1-(scale-1)*(x2-x1)/2))\n            # x_max=int(min(w-1,x2+(scale-1)*(x2-x1)/2))\n            # y_min=int(max(0,y1-(scale-1)*(y2-y1)/2))\n            # y_max=int(min(h-1,y2+(scale-1)*(y2-y1)/2))\n            # sub_image=image[:,y_min:y_max,x_min:x_max].permute((1,2,0)).detach().numpy().astype(np.uint8)\n\n            #########################################################################################################################################################\n            # Failed method: tried shrinking the images by a multiplicative factor to reduce the number of false positive port identifications during classification.\n            # Despite reducing false positives in the classification test, the model behaved strangely during object detection; only identifying background.\n            # Probably need to investigate this more.\n\n            # remove area from the size (take the center 25% of image)\n            scale=0.5\n            x_remove=scale*(x2-x1)/2\n            y_remove=scale*(y2-y1)/2\n            x_min=int(x1+x_remove)\n            x_max=int(x2-x_remove)\n            y_min=int(y1+y_remove)\n            y_max=int(y2-y_remove)\n\n            # get sub-images\n            sub_image=image[:,y_min:y_max,x_min:x_max].permute((1,2,0)).detach().numpy().astype(np.uint8)\n\n            #########################################################################################\n            # Failed mathod: just extracting the boxes with no modifications.\n            # Did not produce usable results when running the image classifier through the sliding window.\n            # High\n\n            # sub_image=image[:,y1:y2,x1:x2].permute((1,2,0)).detach().numpy().astype(np.uint8)\n            \n            plt.imsave(name,sub_image)\n\n    # ***************************************************************************\n    # --------------------------- Save List of Data -----------------------------\n    # ***************************************************************************\n    \n    images=neg_images+pos_images\n    labels=neg_labels+pos_labels\n    with open(f'/kaggle/working/{subset}_images.pkl','wb') as f:\n        pickle.dump(images, f)\n    with open(f'/kaggle/working/{subset}_labels.pkl','wb') as f:\n        pickle.dump(labels, f)\n\n\ngenerate_samples('test')\ngenerate_samples('train')\ngenerate_samples('valid')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T16:52:26.537416Z","iopub.execute_input":"2025-08-29T16:52:26.537734Z","iopub.status.idle":"2025-08-29T16:52:26.657053Z","shell.execute_reply.started":"2025-08-29T16:52:26.537709Z","shell.execute_reply":"2025-08-29T16:52:26.655632Z"}},"outputs":[],"execution_count":null}]}