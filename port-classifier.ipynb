{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":258751239,"sourceType":"kernelVersion"},{"sourceId":258926139,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ***************************************************************************\n# --------------------------------- Imports ---------------------------------\n# ***************************************************************************\n\nimport numpy as np # linear algebra\n\nimport os # file handling\nimport json # file handling\nimport pickle # file handling\nimport zipfile # file handling\n\nimport torch # deep learning\nimport torch.nn as nn # model architecture components\nimport torchvision # deep learning for computer vision\nfrom torch.utils.data import Dataset # shortcuts for writing dataset\n\nimport tqdm # progress bar\n\nimport PIL # image processing\n\nimport random # for data loader\n\nimport cv2 # image processing","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T15:42:51.716517Z","iopub.execute_input":"2025-09-04T15:42:51.716737Z","iopub.status.idle":"2025-09-04T15:43:01.144015Z","shell.execute_reply.started":"2025-09-04T15:42:51.716716Z","shell.execute_reply":"2025-09-04T15:43:01.143447Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ***************************************************************************\n# --------------- Image Classification Dataset Class ------------------------\n# ***************************************************************************\n\nclass PortClassificationDataset(Dataset):\n    def __init__(self,root,pkl_images,pkl_labels,image_size=(128,128),max_len=None):\n        '''\n        dataset for Port\n\n        arguments\n            root: the path of the zip file containing the data\n            pkl_images: the path of the pickled (list) version of the image filenames within the zip folder\n            pkl_labels: the path of the pickled (list) version of the image classes within the zip folder\n\n        Note that roboflow did all the transforming before we downloaded the data. If we need more transformations, we can go back and download the unedited version, then implement our own transformations.\n        '''\n        self.root=root\n        self.image_size=image_size\n        print(f'opening zipped data...')\n        self.zf=zipfile.ZipFile(self.root,'r')\n        # get other parameters from zipped outputs of port-dataset-for-classification\n        print(f'loading labels...')\n        with self.zf.open(pkl_labels,'r') as labels:\n            self.labels=pickle.load(labels)\n        print(f'loading images...')\n        with self.zf.open(pkl_images,'r') as images:\n            self.images=pickle.load(images)\n\n        # -------------- balance classes -------------- #\n        # numbers of each class\n        labels0_idx=[]\n        labels1_idx=[]\n        labels2_idx=[]\n        print(f'length of labels: {len(self.labels)}')\n        for i,label in enumerate(self.labels):\n            if label.item()==0:\n                labels0_idx.append(i)\n            if label.item()==1:\n                labels1_idx.append(i)\n            if label.item()==2:\n                labels2_idx.append(i)\n        # number of instances of the smaller class\n        num_positive_labels=min(len(labels1_idx),len(labels2_idx),len(labels0_idx))\n        # random sample of classes 1 and 2, entire population of class 0\n        idx0=random.sample(labels0_idx,k=num_positive_labels)\n        idx1=random.sample(labels1_idx,k=num_positive_labels)\n        idx2=random.sample(labels2_idx,k=num_positive_labels)\n        # images and labels for class 0\n        labels0=[self.labels[i] for i in idx0]\n        images0=[self.images[i] for i in idx0]\n        # images and labels for class 1\n        labels1=[self.labels[i] for i in idx1]\n        images1=[self.images[i] for i in idx1]\n        # images and labels for class 2\n        labels2=[self.labels[i] for i in idx2]\n        images2=[self.images[i] for i in idx2]\n        # reconstruct data lists\n        self.labels=labels0+labels1+labels2\n        self.images=images0+images1+images2\n\n        # ---------------- enforce max length constraint ------------------- #\n        if max_len is not None and max_len<len(self.labels):\n            subsample_idx=random.sample(range(len(self.labels)),k=max_len)\n            self.labels=[self.labels[i] for i in subsample_idx]\n            self.images=[self.images[i] for i in subsample_idx]\n\n        # ---------------- transforms ------------------- #\n        self.transforms=torchvision.transforms.Compose([\n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Resize(self.image_size),\n            torchvision.transforms.RandomAffine(degrees=2.5,translate=(0.01,0.01),shear=1.5),\n            torchvision.transforms.ColorJitter(brightness=0.1,contrast=0.1,saturation=0.1),     \n            torchvision.transforms.CenterCrop(size=(72,72)),\n            torchvision.transforms.Resize(size=(64,64))\n        ])\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self,idx):\n        if type(idx) is not int:\n            raise ValueError(f'expected idx to be an integer, got {type(idx)}')\n        with self.zf.open(self.images[idx],'r') as img:\n            image=self.transforms(np.copy(np.asarray(PIL.Image.open(img))))\n        label=self.labels[idx]\n        return image,label\n\n    def get_label_counts(self):\n        counts={}\n        for l in self.labels:\n            c=counts.get(l.item(),0)\n            counts[l.item()]=c+1\n        return counts\n\ntrain_dataset=PortClassificationDataset(\n    '/kaggle/input/port-dataset-for-classification/_output_.zip',\n    'train_images.pkl',\n    'train_labels.pkl'\n)\ntest_dataset=PortClassificationDataset(\n    '/kaggle/input/port-dataset-for-classification/_output_.zip',\n    'test_images.pkl',\n    'test_labels.pkl',\n    # max_len=400\n)\nvalid_dataset=PortClassificationDataset(\n    '/kaggle/input/port-dataset-for-classification/_output_.zip',\n    'valid_images.pkl',\n    'valid_labels.pkl',\n    max_len=400\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:54:39.193091Z","iopub.execute_input":"2025-08-28T18:54:39.193479Z","iopub.status.idle":"2025-08-28T18:54:52.630547Z","shell.execute_reply.started":"2025-08-28T18:54:39.193451Z","shell.execute_reply":"2025-08-28T18:54:52.629955Z"}},"outputs":[{"name":"stdout","text":"opening zipped data...\nloading labels...\nloading images...\nlength of labels: 131119\nopening zipped data...\nloading labels...\nloading images...\nlength of labels: 1235\nopening zipped data...\nloading labels...\nloading images...\nlength of labels: 2308\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ***************************************************************************\n# ---------------------- Custom Data Loader ---------------------------------\n# ***************************************************************************\n# PyTorch's data loader class did not work for the original object detection task we trained for.\n# Thus, this class was created as a custom dataloader, and was never replaced once we switched to classification.\n# As such, the training loop is subtly different from the typical PyTorch training loop.\n\nclass PortClassificationDataLoader():\n    def __init__(self,dataset,batch_size):\n        self.dataset=dataset\n        self.batch_size=batch_size\n        self.epochs_completed=0\n        self.current_batch_index_order=random.sample(range(len(self.dataset)),k=len(self.dataset))\n        self.batch_index=0\n\n    def _get_new_batch_order(self):\n        self.current_batch_index_order=random.sample(range(len(self.dataset)),k=len(self.dataset))\n        self.batch_index=0\n        self.epochs_completed+=1\n\n    def get_batch(self):\n        if self.batch_index+self.batch_size>=len(self.dataset):\n            self._get_new_batch_order()\n        images=torch.stack([self.dataset[idx][0] for idx in self.current_batch_index_order[self.batch_index:self.batch_index+self.batch_size]],dim=0)\n        labels=torch.stack([self.dataset[idx][1] for idx in self.current_batch_index_order[self.batch_index:self.batch_index+self.batch_size]],dim=0)\n        self.batch_index+=self.batch_size\n        return images,labels\n\n    def reset(self):\n        self._get_new_batch_order\n        self.epochs_completed=0\n\n    def get_percent_of_epoch_used(self):\n        return self.batch_index/len(self.dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:54:52.631835Z","iopub.execute_input":"2025-08-28T18:54:52.632105Z","iopub.status.idle":"2025-08-28T18:54:52.638804Z","shell.execute_reply.started":"2025-08-28T18:54:52.632086Z","shell.execute_reply":"2025-08-28T18:54:52.638032Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ***************************************************************************\n# ---------------------- ResNet18 Implementation ----------------------------\n# ***************************************************************************\n# Inspired heavily by PyTorch's implementation, but customized for our use-case.\n\ndef conv3x3(in_planes:int,out_planes:int,stride:int=1,groups:int=1,dilation:int=1)->nn.Conv2d:\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(\n        in_planes,\n        out_planes,\n        kernel_size=3,\n        stride=stride,\n        padding=dilation,\n        groups=groups,\n        bias=False,\n        dilation=dilation,\n    )\n\n\ndef conv1x1(in_planes:int,out_planes:int,stride:int=1)->nn.Conv2d:\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes,out_planes,kernel_size=1,stride=stride,bias=False)\n    \n\nclass BottleneckBlock(nn.Module): # size halves iff we multiply channels by 2 (architecture decision, not code enforced)\n    def __init__(self,in_channels,out_channels,stride):\n        \"\"\"\n        Basic residual building block of the resnet.\n        \"\"\"\n        super(BottleneckBlock,self).__init__()\n        self.conv1=conv1x1(in_channels,in_channels)\n        self.bn1=nn.BatchNorm2d(in_channels) \n        self.conv2=conv3x3(in_channels,out_channels,stride) # Use the Bottleneck approach (downsample input on 3x3 conv)\n        self.bn2=nn.BatchNorm2d(out_channels)\n        self.conv3=conv1x1(out_channels,out_channels)\n        self.bn3=nn.BatchNorm2d(out_channels)\n        self.relu=nn.ReLU(inplace=True)\n        self.stride=stride\n        self.identity=lambda x: x\n        # reshape residual connection to match outputs (need to downsamples)\n        if stride!=1 or in_channels!=out_channels:\n             self.identity = nn.Sequential(\n                conv1x1(in_channels,out_channels,stride),\n                nn.BatchNorm2d(out_channels)\n            )\n\n\n    def forward(self,x:torch.Tensor)->torch.Tensor:\n        out=self.conv1(x)\n        out=self.bn1(out)\n        out=self.relu(out)\n        \n        out=self.conv2(out)\n        out=self.bn2(out)\n        out=self.relu(out)\n        \n        out=self.conv3(out)\n        out=self.bn3(out)\n        out+=self.identity(x)\n        out=self.relu(out)\n\n        return out\n\n\nclass ResNet18(nn.Module):\n    def __init__(self,num_classes:int):\n        \"\"\"\n        Creates a ResNet18 module with num_classes classes.\n        \"\"\"\n        super(ResNet18,self).__init__()\n        self.num_classes=num_classes\n        self.in_channels=64 # update the in_channels for the next layer after we make a layer\n        \n        self.conv1=nn.Conv2d(in_channels=3,out_channels=self.in_channels,kernel_size=(7,7),stride=2)\n        self.bn1=nn.BatchNorm2d(self.in_channels)\n        self.relu=nn.ReLU(inplace=True)\n        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n\n        self.layer1=self._make_layer(out_channels=self.in_channels,stride=1) #in_channels=64\n        self.layer2=self._make_layer(out_channels=self.in_channels*2,stride=2) #in_channels=64\n        self.layer3=self._make_layer(out_channels=self.in_channels*2,stride=2) #in_channels=128\n        self.layer4=self._make_layer(out_channels=self.in_channels*2,stride=2) #in_channels=256\n\n        self.avgpool=nn.AdaptiveAvgPool2d(output_size=(1,1))\n        self.fc=nn.Linear(in_features=self.in_channels,out_features=self.num_classes)\n\n        self.softmax=nn.Softmax(dim=1)\n\n        # initialize weights using Kaiming initialization\n        self.apply(self._init_weights)\n\n    \n    def forward(self,x:torch.Tensor)->torch.Tensor:\n        x=self.conv1(x)\n        x=self.bn1(x)\n        x=self.relu(x)\n        x=self.maxpool(x)\n        \n        x=self.layer1(x)\n        x=self.layer2(x)\n        x=self.layer3(x)\n        x=self.layer4(x)\n\n        x=self.avgpool(x)\n        x=torch.flatten(x,1)\n        x=self.fc(x)\n\n        return x\n\n\n    def predict(self,x):\n        probs=self.softmax(self.forward(x))\n        return torch.argmax(probs,axis=1)\n        \n\n    def _make_layer(self,out_channels:int,stride:int)->nn.Sequential:\n        \"\"\"\n        Makes a block layer.\n        The first block has stride 1 to preserve the dimension of the input, and the second block has stride \"stride\" to achieve the output dimension.\n        \"\"\"\n        layer=nn.Sequential(\n            BottleneckBlock(self.in_channels,out_channels,1),\n            BottleneckBlock(out_channels,out_channels,stride)\n        )\n        self.in_channels=out_channels\n        return layer\n\n\n    def _init_weights(self,m):\n        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n            # Kaiming initialization (good for ReLU-based nets)\n            nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n            if m.bias is not None:\n                nn.init.constant_(m.bias,0.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:54:52.639462Z","iopub.execute_input":"2025-08-28T18:54:52.639721Z","iopub.status.idle":"2025-08-28T18:54:52.772552Z","shell.execute_reply.started":"2025-08-28T18:54:52.639696Z","shell.execute_reply":"2025-08-28T18:54:52.771797Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ***************************************************************************\n# --------------------------- Training Function -----------------------------\n# ***************************************************************************\n\ndef train(model,loader,val_loader,epochs,criterion,optim,device,initial_lr=0.1):\n    \"\"\"\n    Train the model on the given loader\n    \n    Args:\n        model (torch.nn.Module): classifier to evaluate.\n        loader (PortClassificationDataLoader): data loader for the training set.\n        val_loader (PortClassificationDataLoader): data loader for the validation set.\n        criterion (callable): loss function.\n        optim (torch.optim): optimizer class (NOT an instance of an optimizer. e.g. torch.optim.SGD or torch.optim.ADAM)\n        device (torch.device or string): device to use for training and evaluation.\n\n    Returns:\n        list[float]: the losses for each batch.\n    \"\"\"\n    learning_rate=initial_lr\n    print(f'[INFO] Training model with learning rate {learning_rate}...')\n    optimizer=optim(model.parameters(),lr=learning_rate)\n    \n    model=model.to(device)\n    pbar=tqdm.notebook.tqdm(total=len(loader.dataset),desc=f'Epoch {loader.epochs_completed+1}/{epochs}')\n    cur_epoch=0\n    last_lr_update=0\n    best_accuracy=0\n    train_losses=[]\n    val_losses=[]\n    val_accuracies=[]\n\n    while loader.epochs_completed<epochs:\n        model.train()\n        inputs,labels=loader.get_batch()\n        inputs=inputs.to(device)\n        labels=labels.to(device)\n        \n        optimizer.zero_grad()\n        logits=model(inputs)\n        loss=criterion(logits,labels)\n    \n        loss.backward()\n        optimizer.step()\n        train_losses.append(loss.item())\n\n        # end of epoch triggers\n        if loader.epochs_completed>cur_epoch:\n            val_loss,val_accuracy=evaluate(model,val_loader,criterion,device)\n            val_losses.append(val_loss)\n            val_accuracies.append(val_accuracy)\n            print(f'Epoch {loader.epochs_completed} Validation Loss = {val_loss:.5f}\\tValidation Accuracy = {val_accuracy:.4f}')\n            cur_epoch=loader.epochs_completed\n            # save weights\n            torch.save(model.state_dict(),'/kaggle/working/model_weights.path')\n            # udpate best weights\n            if val_accuracy>best_accuracy:\n                torch.save(model.state_dict(),'/kaggle/working/best_weights.pth')\n                best_accuracy=val_accuracy\n        # print loss every 100 batches\n        if int(loader.batch_index/loader.batch_size)%250==0:\n            val_loss,val_accuracy=evaluate(model,val_loader,criterion,device)\n            val_losses.append(val_loss)\n            val_accuracies.append(val_accuracy)\n            print(f'\\tBatch {int(loader.batch_index/loader.batch_size)} of Epoch {loader.epochs_completed+1}: Validation Loss = {val_loss:.5f}\\tValidation Accuracy = {val_accuracy:.4f}')\n        \n        # update learning rate if loss stagnates\n        if len(val_losses)>0:\n            long_moving_avg_loss=np.mean(val_losses[-35:])\n            short_moving_avg_loss=np.mean(val_losses[-15:])\n            if loader.epochs_completed>10 and last_lr_update>100 and abs(long_moving_avg_loss-short_moving_avg_loss)<0.005:\n                last_lr_update=0\n                print(f'\\t\\tEpoch {loader.epochs_completed+1}: decreasing learning rate from {learning_rate} to {learning_rate/10}')\n                learning_rate/=10\n                optimizer=optim(model.parameters(),lr=learning_rate)\n\n        # update progress bar\n        pbar.n=int(loader.get_percent_of_epoch_used()*len(loader.dataset))\n        pbar.set_description(f'Epoch {loader.epochs_completed+1}/{epochs}\\tLoss = {loss.item():.5f}')\n        pbar.update()\n    # reset loader for if we train after this\n    loader.reset()\n    \n    return train_losses,val_losses,val_accuracies\n\n\ndef evaluate(model,test_loader,criterion,device):\n    \"\"\"\n    Evaluate the classifier on the test set.\n\n    Args:\n        model: classifier to evaluate.\n        test_loader (torch.utils.data.DataLoader): Data loader for the test set.\n        criterion (callable): Loss function to use for evaluation.\n        device (torch.device): Device to use for evaluation.\n\n    Returns:\n        float: Average loss on the test set.\n        float: Accuracy on the test set.\n    \"\"\"\n    model=model.to(device)\n    model.eval()\n    with torch.no_grad():\n        total_loss = 0.0\n        num_correct = 0\n        num_samples = 0\n\n        while test_loader.epochs_completed<1:\n            inputs,labels=test_loader.get_batch()\n            inputs=inputs.to(device)\n            labels=labels.to(device)\n            # compute the logits and loss\n            logits=model(inputs)\n            total_loss+=criterion(logits,labels).item()\n            # compute the accuracy\n            _,predictions=torch.max(logits,dim=1)\n            num_correct+=(predictions==labels).sum().item()\n            num_samples+=len(inputs)\n\n    # reset the validation loader\n    test_loader.reset()\n    # print(f'\\t\\tnumber of samples examined during validation: {num_samples}')\n    # compute the average loss and accuracy\n    avg_loss=total_loss/len(test_loader.dataset)\n    accuracy=num_correct/num_samples\n\n    return avg_loss,accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:55:05.795861Z","iopub.execute_input":"2025-08-28T18:55:05.796162Z","iopub.status.idle":"2025-08-28T18:55:05.808567Z","shell.execute_reply.started":"2025-08-28T18:55:05.796139Z","shell.execute_reply":"2025-08-28T18:55:05.807712Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ***************************************************************************\n# ----------------------------- Run Training --------------------------------\n# ***************************************************************************\n\n# training variables\nloader=PortClassificationDataLoader(train_dataset,256)\nval_loader=PortClassificationDataLoader(valid_dataset,50)\nmodel=ResNet18(3)\nstate_dict = torch.load('/kaggle/input/port-classifier/best_weights.pth')\nmodel.load_state_dict(state_dict)\ncriterion=torch.nn.CrossEntropyLoss()\noptim=torch.optim.Adam\ndevice='cuda'\n\n# training periods (coarsely train, then fine tune with smaller learning rate)\n# train(model,loader,val_loader,9,criterion,optim,device,initial_lr=0.1)\n# train(model,loader,val_loader,7,criterion,optim,device,initial_lr=0.01)\n# train(model,loader,val_loader,7,criterion,optim,device,initial_lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:55:07.533902Z","iopub.execute_input":"2025-08-28T18:55:07.534613Z","iopub.status.idle":"2025-08-28T18:55:08.414746Z","shell.execute_reply.started":"2025-08-28T18:55:07.534580Z","shell.execute_reply":"2025-08-28T18:55:08.413958Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ***************************************************************************\n# ------------------------------ Test Model ---------------------------------\n# ***************************************************************************\n\ntest_loader=PortClassificationDataLoader(test_dataset,32)\ncriterion=torch.nn.CrossEntropyLoss()\navg_loss,avg_accuracy=evaluate(model,test_loader,criterion,device)\nprint(f'average test-set accuracy: {avg_accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:56:03.631014Z","iopub.execute_input":"2025-08-28T18:56:03.631510Z","iopub.status.idle":"2025-08-28T18:56:05.330873Z","shell.execute_reply.started":"2025-08-28T18:56:03.631485Z","shell.execute_reply":"2025-08-28T18:56:05.330118Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ***************************************************************************\n# -------------------------- Further Evaluation -----------------------------\n# ***************************************************************************\n\ndef confusion_matrix(model,dataset,device):\n    model.eval()\n    model.to(device)\n    # ground-truth labels\n    gt=[l.item() for l in dataset.labels]\n\n    # predicted labels (run entire dataset as one batch)\n    batch=torch.stack([d[0] for d in dataset],dim=0).to(device)\n    preds=[p.item() for p in model.predict(batch)]\n\n    # class 0 specific statistics\n    FN0=[] # incorrectly say a 0 label is 1 or 2\n    FP0=[] # incorrectly say a 1 or 2 label is 0\n    TP0=[] # correctly identify a label 0\n    \n    # class 1 specific statistics\n    FN1=[] # incorrectly say a 1 label is 0 or 2\n    FP1=[] # incorrectly say a 0 or 2 label is 1\n    TP1=[] # correctly identify a label 1\n\n    # class 2 specific statistics\n    FN2=[] # incorrectly say a 2 label is 0 or 1\n    FP2=[] # incorrectly say a 0 or a 1 label is 2\n    TP2=[] # correctly identify a label 2\n\n    # general statistics\n    FN=[] # incorrectly say a 1 or 2 label is 0\n    FP=[] # incorrectly say a 0 label is 1 or 2\n    TN=[] # correctly identify 0\n    TP=[] # correctly identify 1 or 2\n    \n    for i in range(len(preds)):\n        # ---------- class 0 stats ---------- #\n        if preds[i]!=0 and gt[i]==0:\n            FN0.append(i)\n        if preds[i]==0 and gt[i]!=0:\n            FP0.append(i)\n        if preds[i]==gt[i] and gt[i]==0:\n            TP0.append(i)\n        # ---------- class 1 stats ---------- 3\n        if preds[i]!=1 and gt[i]==1:\n            FN1.append(i)\n        if preds[i]==1 and gt[i]!=1:\n            FP1.append(i)\n        if preds[i]==gt[i] and gt[i]==1:\n            TP1.append(i)\n        # ---------- class 2 stats ---------- #\n        if preds[i]!=2 and gt[i]==2:\n            FN2.append(i)\n        if preds[i]==2 and gt[i]!=2:\n            FP2.append(i)\n        if preds[i]==gt[i] and gt[i]==2:\n            TP2.append(i)\n        # ---------- general stats ---------- #\n        # all false negatives\n        if preds[i]==0 and gt[i]!=0:\n            FN.append(i)\n        # all false positives\n        if preds[i]!=0 and gt[i]==0:\n            FP.append(i)\n        # all true negatives\n        if preds[i]==0 and gt[i]==0:\n            TN.append(i)\n        # all true positives (1 or 2)\n        if (preds[i]== 1 and gt[i]==1) or (preds[i]==2 and gt[i]==2):\n            TP.append(i)\n\n    return {\n        0:{'FN':FN0,'FP':FP0,'TP':TP0},\n        1:{'FN':FN1,'FP':FP1,'TP':TP1},\n        2:{'FN':FN2,'FP':FP2,'TP':TP2},\n        -1:{'FN':FN,'FP':FP,'TN':TN,'TP':TP}\n    }\n\nstats=confusion_matrix(model,test_dataset,'cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:56:11.424236Z","iopub.execute_input":"2025-08-28T18:56:11.424894Z","iopub.status.idle":"2025-08-28T18:56:11.856577Z","shell.execute_reply.started":"2025-08-28T18:56:11.424872Z","shell.execute_reply":"2025-08-28T18:56:11.855834Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def analyze_confusion_matrix(m,dataset):\n    print(f'Analzing confusion matrix.See the function confusion_matrix() for explanations.')\n    class_labels=['background','empty','connected']\n    for c in [0,1,2]:\n        stats=m[c]\n        print(f'Class number: {c}, Class label: {class_labels[c]}')\n        print(f'\\tNumber of :\\t{len(stats[\"FN\"])},\\t% of total:\\t{100*len(stats[\"FN\"])/len(dataset):.3f}%')\n        print(f'\\tNumber of FP:\\t{len(stats[\"FP\"])},\\t% of total:\\t{100*len(stats[\"FP\"])/len(dataset):.3f}%')\n        print(f'\\tNumber of TP:\\t{len(stats[\"TP\"])},\\t% of total:\\t{100*len(stats[\"TP\"])/len(dataset):.3f}%')\n        \n    stats=m[-1]\n    print('General statistics:')\n    print(f'\\tNumber of FN:\\t{len(stats[\"FN\"])},\\t% of total:\\t{100*len(stats[\"FN\"])/len(dataset):.3f}%')\n    print(f'\\tNumber of FP:\\t{len(stats[\"FP\"])},\\t% of total:\\t{100*len(stats[\"FP\"])/len(dataset):.3f}%')\n    print(f'\\tNumber of TN:\\t{len(stats[\"TN\"])},\\t% of total:\\t{100*len(stats[\"TN\"])/len(dataset):.3f}%')\n    print(f'\\tNumber of TP:\\t{len(stats[\"TP\"])},\\t% of total:\\t{100*len(stats[\"TP\"])/len(dataset):.3f}%')\n\nanalyze_confusion_matrix(stats,test_dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}